{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, isnull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sparksession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"data_cleaning.ipynb\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and read csv. file\n",
    "file_path = \"project_dataset/python_raw_data/fake_orders_test_1.csv\"\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True, sep=';') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------+------------+-------------+---------------+--------------+--------+------------------+--------------------+\n",
      "|order_id|activation_time_local|country_code|store_address|final_status   |payment_status|products|products_total    |purchase_total_price|\n",
      "+--------+---------------------+------------+-------------+---------------+--------------+--------+------------------+--------------------+\n",
      "|31503775|2019-03-01 11:43:08  |ES          |15871        |DeliveredStatus|PAID          |1       |1.85              |14.02               |\n",
      "|31503965|2019-03-01 11:43:08  |ES          |15871        |DeliveredStatus|PAID          |3       |6.15              |12.21               |\n",
      "|31636675|2019-03-01 08:58:01  |AR          |61807        |DeliveredStatus|PAID          |4       |1.1800000000000002|9.76                |\n",
      "|31724509|2019-03-01 16:43:04  |ES          |16228        |DeliveredStatus|PAID          |5       |11.07             |12.52               |\n",
      "|31839133|2019-03-01 08:43:24  |BR          |20443        |DeliveredStatus|PAID          |1       |1.29              |11.19               |\n",
      "|31848304|2019-03-01 07:33:01  |BR          |49346        |CanceledStatus |PAID          |8       |6.01              |0.0                 |\n",
      "|31867130|2019-03-01 10:03:11  |ES          |18683        |DeliveredStatus|PAID          |9       |17.72             |17.71               |\n",
      "|31867210|2019-03-01 12:03:07  |IT          |12347        |CanceledStatus |PAID          |2       |18.0              |0.0                 |\n",
      "|31868928|2019-03-01 10:03:07  |ES          |29445        |DeliveredStatus|PAID          |18      |24.65             |31.68               |\n",
      "|31876071|2019-03-01 09:03:08  |ES          |16217        |CanceledStatus |PAID          |8       |12.87             |12.69               |\n",
      "+--------+---------------------+------------+-------------+---------------+--------------+--------+------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new = spark.read.csv(file_path, header=True, inferSchema=True, sep=\";\")\n",
    "del df_new  # delete incorrectly created df\n",
    "df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- activation_time_local: timestamp (nullable = true)\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- store_address: integer (nullable = true)\n",
      " |-- final_status: string (nullable = true)\n",
      " |-- payment_status: string (nullable = true)\n",
      " |-- products: integer (nullable = true)\n",
      " |-- products_total: double (nullable = true)\n",
      " |-- purchase_total_price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show schema of the dataframe\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column \"authorised_or_not\" based on \"products_total\"&\"purchase_total_price\"\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"authorized_or_not\",\n",
    "    when(df[\"products_total\"]<df[\"purchase_total_price\"], \"under_authorized\")\n",
    "    .otherwise(\"correctly_authorized\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------+------------+-------------+---------------+--------------+--------+------------------+--------------------+--------------------+\n",
      "|order_id|activation_time_local|country_code|store_address|   final_status|payment_status|products|    products_total|purchase_total_price|   authorized_or_not|\n",
      "+--------+---------------------+------------+-------------+---------------+--------------+--------+------------------+--------------------+--------------------+\n",
      "|31503775|  2019-03-01 11:43:08|          ES|        15871|DeliveredStatus|          PAID|       1|              1.85|               14.02|    under_authorized|\n",
      "|31503965|  2019-03-01 11:43:08|          ES|        15871|DeliveredStatus|          PAID|       3|              6.15|               12.21|    under_authorized|\n",
      "|31636675|  2019-03-01 08:58:01|          AR|        61807|DeliveredStatus|          PAID|       4|1.1800000000000002|                9.76|    under_authorized|\n",
      "|31724509|  2019-03-01 16:43:04|          ES|        16228|DeliveredStatus|          PAID|       5|             11.07|               12.52|    under_authorized|\n",
      "|31839133|  2019-03-01 08:43:24|          BR|        20443|DeliveredStatus|          PAID|       1|              1.29|               11.19|    under_authorized|\n",
      "|31848304|  2019-03-01 07:33:01|          BR|        49346| CanceledStatus|          PAID|       8|              6.01|                 0.0|correctly_authorized|\n",
      "|31867130|  2019-03-01 10:03:11|          ES|        18683|DeliveredStatus|          PAID|       9|             17.72|               17.71|correctly_authorized|\n",
      "|31867210|  2019-03-01 12:03:07|          IT|        12347| CanceledStatus|          PAID|       2|              18.0|                 0.0|correctly_authorized|\n",
      "|31868928|  2019-03-01 10:03:07|          ES|        29445|DeliveredStatus|          PAID|      18|             24.65|               31.68|    under_authorized|\n",
      "|31876071|  2019-03-01 09:03:08|          ES|        16217| CanceledStatus|          PAID|       8|             12.87|               12.69|correctly_authorized|\n",
      "|31890972|  2019-03-02 09:03:08|          FR|         3160|DeliveredStatus|          PAID|       2|               6.8|                21.8|    under_authorized|\n",
      "|31892209|  2019-03-01 11:43:01|          RO|        70011|DeliveredStatus|          PAID|       1|             16.44|               16.44|correctly_authorized|\n",
      "|31903191|  2019-03-01 10:03:03|          ES|        15659|DeliveredStatus|          PAID|       1|              1.72|                1.72|correctly_authorized|\n",
      "|31906571|  2019-03-01 09:03:01|          RO|        70011|DeliveredStatus|          PAID|       1|              9.91|                9.91|correctly_authorized|\n",
      "|31908582|  2019-03-01 11:03:04|          AR|        21664|DeliveredStatus|          PAID|       2|              8.07|               14.88|    under_authorized|\n",
      "|31918981|  2019-03-01 10:03:10|          ES|         5273| CanceledStatus|          PAID|       2|             14.94|                 0.0|correctly_authorized|\n",
      "|31934292|  2019-03-01 09:03:10|          ES|        16231|DeliveredStatus|          PAID|       4|              3.86|               24.27|    under_authorized|\n",
      "|31936061|  2019-03-01 16:43:06|          ES|        16276|DeliveredStatus|          PAID|       6|             11.65|               11.87|    under_authorized|\n",
      "|31949705|  2019-03-01 10:03:08|          ES|        29449|DeliveredStatus|          PAID|      10|             20.07|  19.119999999999997|correctly_authorized|\n",
      "|31949773|  2019-03-01 10:43:06|          IT|        10706|DeliveredStatus|          PAID|       3|              6.21|               11.46|    under_authorized|\n",
      "+--------+---------------------+------------+-------------+---------------+--------------+--------+------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------+------------+-------------+------------+--------------+--------+--------------+--------------------+-----------------+\n",
      "|order_id|activation_time_local|country_code|store_address|final_status|payment_status|products|products_total|purchase_total_price|authorized_or_not|\n",
      "+--------+---------------------+------------+-------------+------------+--------------+--------+--------------+--------------------+-----------------+\n",
      "|       0|                    0|           0|            0|           0|             0|       0|             0|                   0|                0|\n",
      "+--------+---------------------+------------+-------------+------------+--------------+--------+--------------+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check null values in df, select each columns and return the count of null values\n",
    "from pyspark.sql.functions import col, isnan, when, count, countDistinct\n",
    "\n",
    "count_null = df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "\n",
    "count_null.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------+------------+-------------+------------+--------------+--------+--------------+--------------------+-----------------+\n",
      "|order_id|activation_time_local|country_code|store_address|final_status|payment_status|products|products_total|purchase_total_price|authorized_or_not|\n",
      "+--------+---------------------+------------+-------------+------------+--------------+--------+--------------+--------------------+-----------------+\n",
      "|   60400|                56255|          23|         5755|           2|             3|      28|          3981|                4367|                2|\n",
      "+--------+---------------------+------------+-------------+------------+--------------+--------+--------------+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# count numbers of distinct values of each columns\n",
    "count_distinct_values = df.agg(*[countDistinct(col(c)).alias(c) for c in df.columns])\n",
    "count_distinct_values.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export csv file \n",
    "output_path = \"project_dataset/python_raw_data/fake_orders_test_updated.csv\"\n",
    "df.coalesce(1).write.option(\"header\", \"true\").csv(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
